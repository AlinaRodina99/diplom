{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlinaRodina99/diplom/blob/main/Inceptionv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF6qEmFHwbxV"
      },
      "outputs": [],
      "source": [
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeMV0gaTw2KT"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "from skimage import io\n",
        "from PIL import Image, ImageFile\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sth9WZnO0QQM",
        "outputId": "4ae2fcaa-4744-42ba-9d93-e1c4db1a0765"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc13b99f170>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.manual_seed(17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hDP83-76X_n"
      },
      "outputs": [],
      "source": [
        "class PaintingsAndPainters(Dataset):\n",
        "  def __init__(self, csv_file, root_dir, transform):\n",
        "    self.annotations = pd.read_csv(csv_file, header=None)\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    y_label = torch.tensor(self.annotations.iloc[index, 1])\n",
        "    img_path = self.root_dir + self.annotations.iloc[index, 0]\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    #transform = transforms.Grayscale()\n",
        "    #image = transform(image)\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    return (image, y_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTDn_6aQw4_h"
      },
      "outputs": [],
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qYajPD3qftS",
        "outputId": "975e25e5-05b5-40bd-f92f-c2066dfe9b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YmAYgb9xUz1"
      },
      "outputs": [],
      "source": [
        "dataset = PaintingsAndPainters(csv_file= 'data_and_labels_init.csv', root_dir = '/content/drive/MyDrive/images_init/', transform = preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8LTGRDYE4mB",
        "outputId": "20f9688c-1adb-46d8-baf7-825d863ebede"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "m = len(dataset)\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KofOtf70QKI7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader,random_split\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35_syvfHx-Vh"
      },
      "outputs": [],
      "source": [
        "generator_ = torch.Generator().manual_seed(17)\n",
        "train_data, val_data = random_split(dataset, [int(m-m*0.1), int(m*0.1)], generator = generator_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgZ8WzHqHRmb"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HB0qFYYzQGX3"
      },
      "outputs": [],
      "source": [
        "batch_size=20\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle = True, num_workers = 1)\n",
        "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle = False, num_workers = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-ptGjIzWZQy"
      },
      "outputs": [],
      "source": [
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hduRrkOntLUD"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhKDfAeHSgvQ"
      },
      "outputs": [],
      "source": [
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY3JFBmjrArx",
        "outputId": "c345c697-b64e-4ae3-cfd1-5e5ca006c9c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100%|██████████| 104M/104M [00:00<00:00, 293MB/s] \n"
          ]
        }
      ],
      "source": [
        "model = models.inception_v3(pretrained=True).to(device)\n",
        "    \n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.fc = nn.Linear(2048, 72).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Un2ta-zETdm"
      },
      "outputs": [],
      "source": [
        "lr = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_SGvlVlrXjh"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optim = torch.optim.SGD(model.fc.parameters(), lr=lr, momentum = 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv62p6Tuu01I"
      },
      "outputs": [],
      "source": [
        "def train_epoch(autoencoder, device, dataloader, loss_fn, optimizer, epoch):\n",
        "    # Set train mode for both the encoder and the decoder\n",
        "    train_loss = []\n",
        "    model.train()\n",
        "    avg_train_loss = 0\n",
        "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
        "    for image_batch, labels in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
        "        # Move tensor to the proper device\n",
        "        image_batch = image_batch.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Evaluate loss\n",
        "        outputs, lala = model(image_batch)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        print('aa')\n",
        "        loss.backward()\n",
        "        print('bb')\n",
        "        optimizer.step()\n",
        "        # Print batch loss\n",
        "        print('\\t partial train loss (single batch): %f' % (loss.data))\n",
        "        avg_train_loss += loss / len(dataloader)\n",
        "    global lr\n",
        "    lr *= 0.8\n",
        "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=lr, weight_decay=1e-05)\n",
        "    return avg_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjI-27CQvYqQ"
      },
      "outputs": [],
      "source": [
        "val_losses = []\n",
        "val_accs = []\n",
        "def test_epoch(autoencoder, device, dataloader, loss_fn):\n",
        "    # Set evaluation mode for encoder and decoder\n",
        "    model.eval()\n",
        "    avg_val_loss = 0\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    with torch.no_grad(): # No need to track the gradients\n",
        "        # Define the lists to store the outputs for each batch\n",
        "        conc_out = []\n",
        "        conc_label = []\n",
        "        for image_batch, labels in dataloader:\n",
        "            # Move tensor to the proper device\n",
        "            #if torch.cuda.is_available():\n",
        "               #print('yes')\n",
        "            image_batch = image_batch.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Decode data\n",
        "            outputs, lala = model(image_batch)\n",
        "            # Append the network output and the original image to the lists\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            avg_val_loss += loss / len(dataloader)\n",
        "            predicted_labels.append(outputs.argmax(dim = 1))\n",
        "            real_labels.append(labels)\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    val_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    return avg_val_loss, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP6Y9ywMtAlR",
        "outputId": "3be710df-3aea-4eec-9fe1-59f2f50b451c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.1872507247830267e-14"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load(\"/content/drive/MyDrive/model.pt\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optim.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "lr = checkpoint['lr']\n",
        "lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "inu4g_7CvlxG",
        "outputId": "5b517a96-6b2e-45df-d14e-5943fe69b700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.407687\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.367241\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.296681\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.412703\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.304887\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.351839\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.283214\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.232338\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.195522\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.328717\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.264086\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.381166\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.179344\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.172641\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.130239\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.033024\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.212395\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.038821\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.090642\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.961256\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.068686\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.962477\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.019862\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.045414\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.170997\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.948439\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.056008\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.933835\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.158046\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.117182\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.803922\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.240806\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.614037\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.090161\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.006248\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.032802\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.197144\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.028606\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.154938\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.031733\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.903733\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.106494\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.798220\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.022086\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.784197\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.895349\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.994033\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.837180\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.238770\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.532473\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.140849\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.644557\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.712798\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.757195\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.494052\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.767251\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.055237\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.419679\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.524823\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.821424\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.652560\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.529066\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.710252\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.096559\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.191483\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.032652\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.966220\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.600578\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.168042\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.366676\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.108508\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.115622\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.048862\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.964828\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.141147\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.927302\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.040973\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.604547\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.953825\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.312681\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.606281\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.551246\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.301982\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.584094\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.558428\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.069695\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.648199\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.954247\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.904917\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.943799\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.900722\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.678520\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.965244\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.988528\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.772450\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.905659\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.767310\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.278176\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.784714\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.063154\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.490762\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.761942\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.794500\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.835798\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.549344\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.961353\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.824694\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.921715\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.824689\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.919823\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.555560\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.668282\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.506721\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.823765\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.672034\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.377356\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.246632\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 2.985977\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.068271\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.881579\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.112446\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.739319\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.509832\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.606309\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.884277\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.703679\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.843889\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.967552\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.662822\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.473613\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.643407\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.037374\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.368526\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.071831\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.280423\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.445456\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.898098\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.080910\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.312900\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.413101\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.152247\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.597369\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.580779\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.750922\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.747871\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.917640\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.768408\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.565370\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.617651\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.126513\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.940254\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.635016\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.950898\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.731365\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.576060\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.720371\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.375307\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.496934\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.773353\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.528872\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.946723\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.062827\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.793806\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.599145\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.783041\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.733623\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.392543\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.499398\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.107594\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.830884\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.609268\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.685212\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.577950\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.638019\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.095452\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.447678\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.741452\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.530202\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.440589\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.562259\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.443031\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.342990\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.581786\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.568982\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.744573\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.452025\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.852751\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.260553\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.054261\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.573907\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.818075\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.653701\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.450129\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.937177\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.867170\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.529650\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.603516\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.213418\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.590427\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.528856\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.571064\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.545826\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.668721\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.482177\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.345887\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.437843\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.571446\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.007811\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.450547\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.608803\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.857383\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.569377\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.740678\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 4.041839\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.749812\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.435144\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.520470\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.005482\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.161906\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.613122\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.601583\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.676622\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.529393\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.953702\n",
            "aa\n",
            "bb\n",
            "\t partial train loss (single batch): 3.641146\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f7527fe1a646>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m    \u001b[0mval_loss_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m    \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m    \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-09f1f92ad629>\u001b[0m in \u001b[0;36mtest_epoch\u001b[0;34m(autoencoder, device, dataloader, loss_fn)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Decode data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlala\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Append the network output and the original image to the lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "counter = 0\n",
        "for epoch in range(num_epochs):\n",
        "   train_loss =train_epoch(model,device, train_loader,loss_fn, optim, epoch)\n",
        "   val_loss_acc = test_epoch(model, device,valid_loader,loss_fn)\n",
        "   val_loss = val_loss_acc[0]\n",
        "   val_acc = val_loss_acc[1]\n",
        "   \n",
        "   torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optim.state_dict(),\n",
        "            'loss': val_loss,\n",
        "            'counter': counter,\n",
        "            'lr' : lr\n",
        "            }, \"/content/drive/MyDrive/model.pt\")\n",
        "   #if epoch > 0:\n",
        "    \n",
        "     #checkpoint = torch.load(\"/content/drive/MyDrive/model.pt\")\n",
        "     #val_loss_prev = checkpoint['loss']\n",
        "     #if val_loss_prev - val_loss <= 0:\n",
        "       #counter += 1\n",
        "       #if counter > 7:\n",
        "        # break\n",
        "   print('\\n EPOCH {}/{} \\t train loss {} \\t val loss {} \\t val acc {}'.format(epoch + 1, num_epochs,train_loss,val_loss, val_acc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8zUtDOKHgEID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(val_losses, label='Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation loss')\n",
        "#plt.grid()\n",
        "plt.legend()\n",
        "#plt.title('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "3q9de8wFgAwD",
        "outputId": "e8fc9fdf-d72b-4004-9138-20402d64e7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85biq2Fbpqew"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for image_batch, labels in valid_loader:\n",
        "    image_batch = image_batch.to(device)\n",
        "    labels = labels.to(device)\n",
        "    y_predicted = model(image_batch)\n",
        "    predicted_labels.append(y_predicted.argmax(dim = 1))\n",
        "    real_labels.append(labels)\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "val_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc"
      ],
      "metadata": {
        "id": "FQyQtPdCgL43",
        "outputId": "1aeeaeaa-0ecf-406d-f43a-840b5dc1b9b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1940)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}